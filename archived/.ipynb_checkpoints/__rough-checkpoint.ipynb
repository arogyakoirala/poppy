{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbe44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import multiprocessing as mp\n",
    "# import numpy as np\n",
    "# import eeconvert as eeconvert\n",
    "# import ee\n",
    "# from datetime import datetime, timedelta\n",
    "# import time\n",
    "\n",
    "\n",
    "# ee.Initialize()\n",
    "\n",
    "# class BestDatesHelper2:\n",
    "#     def __init__(self, grid_shapefile_path, n_cores=1, year=2019):\n",
    "#         self.path = grid_shapefile_path\n",
    "#         self.grid = gpd.read_file(self.path)\n",
    "#         print(f\"Starting process for {len(self.grid.index)} tiles\")\n",
    "#         self.n_cores = n_cores\n",
    "#         self.year = year\n",
    "#         self.dates = self._get_just_dates()\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "#     def _get_just_dates(self):\n",
    "#         dates=[datetime(self.year, 1, 1) + timedelta(i - 1) for i in range(1, 170, 16)]\n",
    "#         date_range=[(x, y) for x, y in zip(dates[:-1], [date-timedelta(1) for date in dates[1:]])]\n",
    "#         just_dates = []\n",
    "#         for start, end in date_range:\n",
    "#             stad=start.date().strftime('%Y-%m-%d')\n",
    "#             endd=end.date().strftime('%Y-%m-%d')\n",
    "#             stadendd = (stad, endd)\n",
    "#             just_dates.append(stadendd)\n",
    "#         return just_dates\n",
    "    \n",
    "        \n",
    "#     def add_dates(self):            \n",
    "#         cpus = self.n_cores\n",
    "#         self.total = 0\n",
    "# #         cpus = 6\n",
    "#         grid_chunks = np.array_split(self.grid, cpus)\n",
    "#         pool = mp.Pool(processes=cpus)\n",
    "#         chunk_processes = [pool.apply_async(self._add_dates_for_chunk, args=(chunk, self.grid)) for chunk in grid_chunks]\n",
    "#         chunk_results = [chunk.get() for chunk in chunk_processes]\n",
    "#         final = gpd.GeoDataFrame(data=None, columns=self.grid.columns, index=self.grid.index)\n",
    "#         final = final.iloc[0:0]\n",
    "#         for chunk in chunk_results:\n",
    "#             final = final.append(chunk)\n",
    "#         final.to_file(self.path, driver=\"GPKG\")\n",
    "#         return final\n",
    "\n",
    "    \n",
    "    \n",
    "#     def _get_all_dates(self, collection):\n",
    "#         def iter_func(image, newlist):\n",
    "#             date = ee.Number.parse(image.date().format(\"YYYYMMdd\"));\n",
    "#             newlist = ee.List(newlist);\n",
    "#             return ee.List(newlist.add(date).sort())\n",
    "#         ymd = collection.iterate(iter_func, ee.List([]))\n",
    "#         return list(ee.List(ymd).reduce(ee.Reducer.frequencyHistogram()).getInfo().keys())\n",
    "        \n",
    "#     def _add_dates_for_chunk(self, gdf_chunk, gdf_complete):\n",
    "#         chunk_copy = gpd.GeoDataFrame(data=None, columns=gdf_complete.columns, index=gdf_complete.index)\n",
    "#         chunk_copy = chunk_copy.iloc[0:0]\n",
    "#         for i, row in gdf_chunk.iterrows():\n",
    "            \n",
    "#             start = time.time()\n",
    "            \n",
    "#             x,y = row.geometry.exterior.coords.xy\n",
    "#             cords = np.dstack((x,y)).tolist()\n",
    "#             g=ee.Geometry.Polygon(cords)\n",
    "#             feature = ee.Feature(g)\n",
    "    \n",
    "#             mod_dataset=ee.ImageCollection('MODIS/061/MOD13Q1').filter(ee.Filter.date(self.dates[0][0], self.dates[-1][1])).filter(ee.Filter.bounds(feature.geometry()))\n",
    "#             ndvi = mod_dataset.select(['NDVI']);\n",
    "#             ndvimax = ndvi.max();\n",
    "#             all_dates = self._get_all_dates(mod_dataset)\n",
    "    \n",
    "#             all_ndvis = ndvi.toArray();\n",
    "#             max_ndvi = all_ndvis.arrayArgmax();\n",
    "#             max_ndvi_tile_image = ee.Image(max_ndvi).arrayProject([0]).arrayFlatten([['maxDate_start', 'band2']]);    \n",
    "#             df = eeconvert.fcToGdf(max_ndvi_tile_image.sample(region=g, factor=1,geometries=True, scale=250)).loc[0]\n",
    "#             date_parsed = all_dates[df['maxDate_start']]\n",
    "#             date_parsed = date_parsed[0:4] + \"-\" + date_parsed[4:6] + \"-\" + date_parsed[6:8]\n",
    "#             row['BSD'] = date_parsed\n",
    "#             chunk_copy = chunk_copy.append(row)\n",
    "#             self.total = self.total + 1\n",
    "#             print(f\"t={(time.time() - start)} | total = {self.total} | i={i} | {df['maxDate_start']} | {all_dates[df['maxDate_start']]}\")\n",
    "#         return chunk_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35401724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils.shapefile import ShapefileHelper\n",
    "from utils.dates import BestDatesHelper\n",
    "from utils.rasters import RasterGenerationHelper\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sh = ShapefileHelper('../data/inputs/aoi.gpkg', '../data4560/interim')\n",
    "sh.make_grid(resolution=2500, name=\"parent\", id_col=\"pgrid_id\")\n",
    "sh.make_grid(resolution=250, name=\"child\")\n",
    "\n",
    "\n",
    "\n",
    "# bdh = BestDatesHelper('../data4560/inputs/best_dates.csv','../data4560/interim/child.gpkg','../data4560/interim', \"child\", 2019, n_neighbors=3, diagnose = True)\n",
    "# bdh.fill_empty_dates()\n",
    "\n",
    "bdh = BestDatesHelper2('../data4560/interim/child.gpkg', n_cores = 5, year = 2019)\n",
    "bdh.add_dates()\n",
    "\n",
    "\n",
    "\n",
    "Path('../data4560/interim/tiles').mkdir(parents=True, exist_ok=True)\n",
    "rgh = RasterGenerationHelper('../data4560/interim/parent.gpkg', '../data4560/interim/child.gpkg', '../data4560/interim/tiles', 10, clean = True, post_period_days = [45,60])\n",
    "rgh.get_rasters()\n",
    "# print(time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= gpd.read_file('../data4560/interim/child.gpkg')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2aec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grid = updated_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540310c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby(['BSD', 'BED']).count()['GRID_ID'].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
